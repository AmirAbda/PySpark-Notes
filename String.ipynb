{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diLLrVPmj2Di",
        "outputId": "ab72856d-6902-4719-d058-acda90dc9689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=fd4d0e833945e7ced7ab93858799943cdca510d94b3c0f694803acc9771e94ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgMvWOszk_lv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Text Algorithm\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "\"\"\" inspired by the intention all you need paper abstract  \"\"\"\n",
        "text = \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.\"\n",
        "\n",
        "rdd = sc.parallelize([text])\n",
        "\n",
        "rdd.collect()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAur35FqlCaW",
        "outputId": "dcec3bfd-88c0-4ddc-e304-1297d81498ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=rdd.flatMap(lambda x: x.split())\n",
        "word_pairs = word.map(lambda x: (x, 1))\n",
        "print(f\" the result {word_pairs.collect()}\" )\n",
        "word_counts = word_pairs.reduceByKey(lambda x, y: x + y)\n",
        "print(f\" the result {word_counts.collect()}\")\n",
        "for  word , count in word_counts.collect():\n",
        "  print(f\"{word} : {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2kc5g3mjhN",
        "outputId": "39a356bc-7090-4c6a-f5c9-5e2b13593792"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the result [('The', 1), ('dominant', 1), ('sequence', 1), ('transduction', 1), ('models', 1), ('are', 1), ('based', 1), ('on', 1), ('complex', 1), ('recurrent', 1), ('or', 1), ('convolutional', 1), ('neural', 1), ('networks', 1), ('in', 1), ('an', 1), ('encoder-decoder', 1), ('configuration.', 1), ('The', 1), ('best', 1), ('performing', 1), ('models', 1), ('also', 1), ('connect', 1), ('the', 1), ('encoder', 1), ('and', 1), ('decoder', 1), ('through', 1), ('an', 1), ('attention', 1), ('mechanism.', 1), ('We', 1), ('propose', 1), ('a', 1), ('new', 1), ('simple', 1), ('network', 1), ('architecture,', 1), ('the', 1), ('Transformer,', 1), ('based', 1), ('solely', 1), ('on', 1), ('attention', 1), ('mechanisms,', 1), ('dispensing', 1), ('with', 1), ('recurrence', 1), ('and', 1), ('convolutions', 1), ('entirely.', 1), ('Experiments', 1), ('on', 1), ('two', 1), ('machine', 1), ('translation', 1), ('tasks', 1), ('show', 1), ('these', 1), ('models', 1), ('to', 1), ('be', 1), ('superior', 1), ('in', 1), ('quality', 1), ('while', 1), ('being', 1), ('more', 1), ('parallelizable', 1), ('and', 1), ('requiring', 1), ('significantly', 1), ('less', 1), ('time', 1), ('to', 1), ('train.', 1)]\n",
            " the result [('The', 2), ('sequence', 1), ('are', 1), ('based', 2), ('recurrent', 1), ('convolutional', 1), ('neural', 1), ('networks', 1), ('in', 2), ('an', 2), ('encoder-decoder', 1), ('best', 1), ('connect', 1), ('encoder', 1), ('decoder', 1), ('mechanism.', 1), ('new', 1), ('simple', 1), ('network', 1), ('architecture,', 1), ('solely', 1), ('dispensing', 1), ('entirely.', 1), ('two', 1), ('machine', 1), ('tasks', 1), ('these', 1), ('quality', 1), ('more', 1), ('requiring', 1), ('significantly', 1), ('dominant', 1), ('transduction', 1), ('models', 3), ('on', 3), ('complex', 1), ('or', 1), ('configuration.', 1), ('performing', 1), ('also', 1), ('the', 2), ('and', 3), ('through', 1), ('attention', 2), ('We', 1), ('propose', 1), ('a', 1), ('Transformer,', 1), ('mechanisms,', 1), ('with', 1), ('recurrence', 1), ('convolutions', 1), ('Experiments', 1), ('translation', 1), ('show', 1), ('to', 2), ('be', 1), ('superior', 1), ('while', 1), ('being', 1), ('parallelizable', 1), ('less', 1), ('time', 1), ('train.', 1)]\n",
            "The : 2\n",
            "sequence : 1\n",
            "are : 1\n",
            "based : 2\n",
            "recurrent : 1\n",
            "convolutional : 1\n",
            "neural : 1\n",
            "networks : 1\n",
            "in : 2\n",
            "an : 2\n",
            "encoder-decoder : 1\n",
            "best : 1\n",
            "connect : 1\n",
            "encoder : 1\n",
            "decoder : 1\n",
            "mechanism. : 1\n",
            "new : 1\n",
            "simple : 1\n",
            "network : 1\n",
            "architecture, : 1\n",
            "solely : 1\n",
            "dispensing : 1\n",
            "entirely. : 1\n",
            "two : 1\n",
            "machine : 1\n",
            "tasks : 1\n",
            "these : 1\n",
            "quality : 1\n",
            "more : 1\n",
            "requiring : 1\n",
            "significantly : 1\n",
            "dominant : 1\n",
            "transduction : 1\n",
            "models : 3\n",
            "on : 3\n",
            "complex : 1\n",
            "or : 1\n",
            "configuration. : 1\n",
            "performing : 1\n",
            "also : 1\n",
            "the : 2\n",
            "and : 3\n",
            "through : 1\n",
            "attention : 2\n",
            "We : 1\n",
            "propose : 1\n",
            "a : 1\n",
            "Transformer, : 1\n",
            "mechanisms, : 1\n",
            "with : 1\n",
            "recurrence : 1\n",
            "convolutions : 1\n",
            "Experiments : 1\n",
            "translation : 1\n",
            "show : 1\n",
            "to : 2\n",
            "be : 1\n",
            "superior : 1\n",
            "while : 1\n",
            "being : 1\n",
            "parallelizable : 1\n",
            "less : 1\n",
            "time : 1\n",
            "train. : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kmp_search(pattern, text):\n",
        "    # Preprocess the pattern to create the partial match table (prefix table)\n",
        "    def build_prefix_table(pattern):\n",
        "        prefix_table = [0] * len(pattern)\n",
        "        j = 0\n",
        "\n",
        "        for i in range(1, len(pattern)):\n",
        "            while (j > 0 and pattern[i] != pattern[j]):\n",
        "                j = prefix_table[j - 1]\n",
        "\n",
        "            if pattern[i] == pattern[j]:\n",
        "                j += 1\n",
        "                prefix_table[i] = j\n",
        "            else:\n",
        "                prefix_table[i] = 0\n",
        "\n",
        "        return prefix_table\n",
        "\n",
        "    # Main KMP search algorithm\n",
        "    prefix_table = build_prefix_table(pattern)\n",
        "    matches = []\n",
        "    j = 0\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        while (j > 0 and text[i] != pattern[j]):\n",
        "            j = prefix_table[j - 1]\n",
        "\n",
        "        if text[i] == pattern[j]:\n",
        "            j += 1\n",
        "\n",
        "        if j == len(pattern):\n",
        "            matches.append(i - j + 1)\n",
        "            j = prefix_table[j - 1]\n",
        "\n",
        "    return matches\n",
        "\n",
        "# Example usage\n",
        "pattern = \"ana\"\n",
        "text = \"banana\"\n",
        "result = kmp_search(pattern, text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zah1W_SoDII",
        "outputId": "3219fce1-23ad-4967-e76d-03a171b3b938"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uje3pOLFnCLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}